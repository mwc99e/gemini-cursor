# Gemini Cursor âœ¨

A second AI cursor ğŸ–±ï¸ for your desktop that can see your screen, hear you speak, and talk to you.

Powered by Google's Gemini 2.0 Flash (Experimental) model, the Multimodal Live API, Pointing, and Function calling capabilities.

Created by [@13point5](https://x.com/27upon2).

## Features

- ğŸ–±ï¸ Second AI cursor on your desktop
- ğŸš€ Multimodality: The model can see ğŸ“¸, hear ğŸ¤, and speak ğŸ”Š
- âš¡ï¸ Real-time with low latency
- ğŸŒ Cross-platform support

## Tech Stack

- Frontend: Electron, React, TypeScript, Vite
- AI: Google Gemini API

## Prerequisites

- Node.js (v16 or higher)
- npm or yarn
- [Gemini API key](https://aistudio.google.com/apikey)

## Acknowledgements

- A lot of code from the Gemini [Multimodal Live API Web console](https://github.com/google-gemini/multimodal-live-api-web-console)
- Built using Google's [Multimodal Live API](https://ai.google.dev/gemini-api/docs/multimodal-live)
